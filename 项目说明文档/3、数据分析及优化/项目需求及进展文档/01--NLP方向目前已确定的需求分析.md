# NLP方向目前已确定的需求分析

### NLP相关：

- 每日答题题库生成
	- 分为三部分
		- 诗词补充：生成范围：高考64首
		- 生活常识
		- 历史典故：炎黄时期至清朝
		
	- 选项长度控制在5个字符左右，10个字符以内
	
	- 补充说明：
	
	  > 针对该需求--
	  >
	  > 1、需要拿到已有的题目数据库，大致了解目前的题目类型、范围
	  >
	  > 2、明确验收标准、找到每日一题的具体项目负责人进行直接沟通
	  >
	  > 3、查看目前已有的相似的解决方案
	  >
	  > 4、收集、了解目前的开源中文语料
	  >
	  > 5、查找适合的方法、进行试验并快速验证
	  >
	  > 6、待补充...
	
- 战报自动生成
	
	事例图片：
	
	<img src="imgs_nlp_research/战报新闻-1.png" alt="战报新闻-1" style="zoom: 33%;" />
	
	
	
	- 生成文字直播
		- 准确传达游戏发生的事件
		- 适当使用游戏内的专业术语
		- 适当带有感情，主要分为常态和高昂态
		
	- 生成文字战报
		- 以游戏内的大事件（如胜率拐点、胜率差变大等）或人物状态变化（如召宠数、物品数每减少3等）将游戏划分为多个阶段，并总结每个阶段发生的事件
		- 总结战斗双方的总体表现，例如胜利方总输出、MVP点评等
		
	- 补充说明：
	
	  > 针对该需求：
	  >
	  > 1、确定可以获取到的数据、可训练的语料格式
	  >
	  > 2、确定验收标准，找到之前负责战报生成的负责人进行直接沟通
	  >
	  > 3、了解目前公司内部的NLP相关的所有预料数据
	  >
	  > 4、查找适合的方法、进行试验并快速验证
	  >
	  > 5、待补充...



### 针对NLP任务的要点归纳：

1. 数据集获取
   - 外部的开源中文语料数据集
   - 公司内部的已有语料数据源
2. 论证需求使用NLP方法进行解决的优劣势及具体的实现方法
3. 查找目前已有的相似问题的解决方法



## 目前已搜集的类似需求记录

### 阿里巴巴的NLP模型应用：

AliceMind 开源地址：https://github.com/alibaba/AliceMind
AliceMind 体验入口：https://nlp.aliyun.com/portal#/alice



## 每日问答的需求推进

手游、端游分别推进

背景介绍：了解目前的游戏中的答题模块的现状，分析是否需要使用NLP或者其他方式进行补充，用来生成更多样性的题目，并满足游戏的使用条件。

首先与直接负责人沟通，探讨是否有做的必要性。

**神武手游：**

- 综合设计-文案-柯学

- 需求描述：

  探讨一下，是否有使用人工智能方法(NLP算法)或者其他算法来生成每日问答题库的需求。

  现状：

  > 目前题库的来源：人工收集或编辑
  >
  > 目前手游的问题是题库较为老旧，玩家根据现有的内容制作了题库，可以自动答题，搜集答案。
  > 但是更新题目的代价比较大，且时效性只有一次，保持长久的大体量更新题库是不太现实的
  > 这里是否能让题目和答案自动生成一些变种，让玩家不能直接用题库搜索

  分析：

  > 手游题库现状：
  >
  > 1、目前题目老旧
  > 2、保持大体量题库比较麻烦
  >
  > 需求：
  > 生成新题库，目的：玩家不能直接搜索得到答案

  综合设计-文案-柯学   观点：

  >  难点：很多题目是常识通识文学、诗词类的知识，所以变幻起来比较麻烦

  题库数据：

  >  手游与端游题目有部分相同



**神武端游**

- 神武4-游戏策划-司羽

- 需求分析

  > 端游的每日答题题目类型为：
  > 传统文化
  > 自然科学
  > 生活百科
  > 游戏知识

- 数据--题库

  已拿到端游题库







# NLP方向在游戏应用上的调研

目标说明：

- 针对神武游戏(手游、端游)中的文本类任务，通过NLP技术进行优化或者替代，达到优化玩家的游戏体验，增强与用户的互动性等效果。



目前可能的需求：

1. 剧情生成类

   即故事线的生成，替代目前较为僵硬的剧本

2. NPC对话类

   目前的NPC对话较为单调，可以通过NLP来增强互动性

3. 对局比赛的战报生成

4. 打宠物的客观评价

   - 需求说明：常见很多人打宠物，然后截图到论坛让大家帮忙看看，给出一些建议

     <img src="imgs_nlp_research/打宝宝评价-1.png" alt="打宝宝评价-1" style="zoom:67%;" />

     <img src="imgs_nlp_research/打宝宝评价-2.png" alt="打宝宝评价-2" style="zoom: 67%;" />

   - 数据源可以采用论坛上的讨论，选取比较客观准确的数据进行整理

   - 目标：玩家给出截图，官方对宠物进行评价，给出一个比较可观的推荐：重新洗、保留、如何培养等需求

5. 每日问答题



问卷调查的问题编写：

1. 神武游戏中，对于NPC与玩家之间的对话互动是否有需求，比如通过交流收集用户的反馈信息来优化玩家的体验
2. 对于奇遇等各种故事线的剧本生成是否有需求，若有可具体谈谈想要的效果
3. 对于每日答题，有哪些具体的约束条件：比如问题范围、难度，想达到怎样的效果
4. 游戏中，是否有其他需要文本处理的需求，可以展开谈谈
5. xxx



目前已有的成功实践案例：

- 实例：https://play.aidungeon.io/main/home

     2019 年 12 月，犹他州初创公司 Latitude 推出了一款名为*AI Dungeon*的开创性在线游戏，展示了一种新的人机协作形式。该公司使用人工智能公司OpenAI 的文本生成技术创建了一款受[龙与地下城](https://www.wired.com/tag/dungeons-and-dragons/)启发的自选冒险游戏。当玩家输入他们希望他们的角色执行的动作或对话时，算法将设计他们个性化的、不可预测的冒险的下一阶段。去年夏天，OpenAI 让 Latitude 抢先体验了其技术的更强大的商业版本。在营销材料中，OpenAI 将*AI Dungeon*吹捧为编写算法的商业和创造潜力的一个例子。

     - 开源地址：https://github.com/Latitude-Archives/AIDungeon

     <img src="../游戏AI调研文档/imgs/figure-3.png" alt="figure-3" style="zoom: 25%;" />

     

     <img src="../游戏AI调研文档/imgs/figure-2.png" alt="figure-2" style="zoom: 33%;" />







# NLP方向的资料收集

数据来源：爱可可爱生活

## paper：

1. NLP From Scratch Without Large-Scale Pretraining: A Simple and Efficient Framework

   - https://arxiv.org/abs/2111.04130

     由于强大的性能，预训练的语言模型已经成为许多NLP任务的标准方法，但它们的训练成本非常高。我们提出了一个简单而高效的学习框架，即TLM，它不依赖于大规模的预训练。给定一些标记的任务数据和一个大型的通用语料库，TLM使用任务数据作为查询，以检索通用语料库的一个极小的子集，并联合优化任务目标和语言建模目标，从头开始。在四个领域的八个分类数据集上，TLM取得了优于或类似于预训练语言模型（如RoBERTa-Large）的结果，同时将训练FLOPs减少了两个数量级。凭借高精确度和高效率，我们希望TLM能够为NLP的民主化和加速其发展作出贡献。





## 大公司的研究项目

1. Textless NLP：从原始音频生成表达性语音

   - https://ai.facebook.com/blog/textless-nlp-generating-expressive-speech-from-raw-audio/

   - FACEBOOK AI

     https://ai.facebook.com/blog/textless-nlp-generating-expressive-speech-from-raw-audio/



## Github资源汇总

1. 基于transformers的自然语言处理(NLP)入门
   - https://github.com/datawhalechina/Learn-NLP-with-Transformers