# NLP的语料数据爬取文档

目标：

- 使用爬虫技术，对网页数据(例如中文维基百科数据)进行信息提取，目的是提取出适用于问题生成的预料数据信息；
- 研究基于标签的定向数据信息的爬取技术，这样可以对不同领域的数据信息进行分类，达到想要获取哪个领域的数据就可以定向进行爬取的目标；

### 学习参考

1. 北邮《Python编程与实践》课程 (2020)--爱可可
   - [哔哩哔哩视频讲解][https://www.bilibili.com/video/BV1b7411N7P2?p=28&spm_id_from=pageDriver]
   - [GitHub代码地址][https://github.com/fly51fly/Practical_Python_Programming]
2. Python爬虫系列讲解
   - [CSDN][https://blog.csdn.net/it_charge/category_10097766.html]



### 所需的库函数

- BeautifulSoup
- Selenium



### 参考的代码实现

1. [jasonhavenD](https://github.com/jasonhavenD)/**[Baike](https://github.com/jasonhavenD/Baike)**
2. [ZXAutomaticBuild](https://github.com/ZXAutomaticBuild)/**[baikeSpider](https://github.com/ZXAutomaticBuild/baikeSpider)**
3. [spider-flow][https://github.com/ssssssss-team/spider-flow]
   - 智能高效的在线爬虫平台
4. [yuyongsheng1990](https://github.com/yuyongsheng1990)/**[python_spider_from_wikipedia](https://github.com/yuyongsheng1990/python_spider_from_wikipedia)**
5. [lixiang0](https://github.com/lixiang0)/**[WEB_KG](https://github.com/lixiang0/WEB_KG)**
6. [coder-pig](https://github.com/coder-pig)/**[PythonSpiderBook](https://github.com/coder-pig/PythonSpiderBook)**



# 开源Web知识图谱项目说明

地址

- https://github.com/lixiang0/WEB_KG
- https://github.com/lixiang0/WEB_KG/issues/20

功能

- 爬取百度百科中文界面
- 解析三元组和页面内容
- 构建中文知识图谱
- 构建百科bot(构建中)



