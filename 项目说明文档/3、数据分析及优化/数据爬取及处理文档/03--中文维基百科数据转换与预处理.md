# 中文维基百科数据转换与预处理

参考：

- github开源代码：

  - https://github.com/wjn1996/scrapy_for_zh_wiki
  - https://github.com/bamtercelboo/corpus_process_script

- wiki数据提取工具
  - https://github.com/attardi/wikiextractor
    - 从维基百科转储中提取纯文本的工具



- wiki dumps开源语料库：

  - https://dumps.wikimedia.org/zhwiki/

  - https://dumps.wikimedia.org/zhwiki/latest/

    - 本次处理的语料为：zhwiki-latest-pages-articles.xml.bz2

    | 中文维基百科                         |        名称        |
    | :----------------------------------- | :----------------: |
    | zhwiki-latest-pages-articles.xml.bz2 |      词条正文      |
    | zhwiki-latest-redirect.sql           | 词条重定向(同义词) |
    | zhwiki-latest-pagelinks.sql          |  词条页面内容外链  |
    | zhwiki-latest-page.sql               |   词条标题及摘要   |
    | zhwiki-latest-categorylinks.sql      |  词条开放分类链接  |

    

### 目录：

1. 中文维基百科网页分析

2. 用来数据提取的代码解析

   



### 1、中文维基百科网页分析

维基百科网站页面除了一些网站必有的功能外，百科类的界面主要有两种，分别是：

- **分类页面：** 对应的URL请求则属于**分类请求**；
- **内容页面：** 对应的URL请求则属于**内容请求**；

分类页面只会存在与该分类相关的关键词实体（下统一称作实体）的超链接URL请求，这些请求也主要分为分类请求和内容请求。对于分类请求则是下一个子类，而内容请求则是该对应实体的详细讲解页面。

分类请求的URL格式为：

- https://zh.wikipedia.org/wiki/Category:xxx

内容请求则是显示实体的具体内容的页面：

- https://zh.wikipedia.org/wiki/xxx





### 2、用来数据提取的代码解析

此处处理的wiki数据：zhwiki-latest-pages-articles.xml.bz2

参考代码：https://github.com/AimeeLee77/wiki_zh_word2vec/blob/master/1_process.py

需要修改代码：

```python
# wiki =WikiCorpus(inp, lemmatize=False, dictionary=[])#gensim里的维基百科处理类WikiCorpus
# 修改为
wiki = WikiCorpus(inp, dictionary=[])
```

此处可查看源代码：

- 地址：[Link-1][https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/corpora/wikicorpus.py]

- ```python
  if lemmatize is not None:
      raise NotImplementedError(
          'The lemmatize parameter is no longer supported. '
          'If you need to lemmatize, use e.g. <https://github.com/clips/pattern>. '
          'Perform lemmatization as part of your tokenization function and '
          'pass it as the tokenizer_func parameter to this initializer.'
      )
  ```



#### 数据抽取

使用指令：

```python
python wiki_process.py zhwiki-latest-pages-articles.xml.bz2 zhwiki-latest.txt
```

处理过后的得到一份中文维基百科正文数据（zhwiki-latest.txt）。


```python
"""
    FILE :  wiki_process.py
    FUNCTION : None
    REFERENCE: https://github.com/AimeeLee77/wiki_zh_word2vec/blob/master/1_process.py
"""

import logging
import os.path
import sys

from gensim.corpora import WikiCorpus

if __name__ == '__main__':
    program = os.path.basename(sys.argv[0])
    logger = logging.getLogger(program)

    logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')
    logging.root.setLevel(level=logging.INFO)
    logger.info("running %s" % ' '.join(sys.argv))

    if len(sys.argv) < 3:
        print(globals()['__doc__'] % locals())
        sys.exit(1)

    inp, outp = sys.argv[1:3]
    space = " "
    i = 0

    output = open(outp, 'w')
    wiki = WikiCorpus(inp, dictionary=[])
    for text in wiki.get_texts():
        output.write(space.join(text) + "\n")
        i = i + 1
        if (i % 10000 == 0):
            logger.info("Saved " + str(i) + " articles.")

    output.close()
    logger.info("Finished Saved " + str(i) + " articles.")
```



#### 中文繁体转简体

使用指令：

```python
python chinese_t2s.py -h
python chinese_t2s.py --input input_file --output output_file
```

代码参考：

- https://github.com/bamtercelboo/corpus_process_script/tree/master/chinese_t2s

```python
import sys
import os
import opencc
from optparse import OptionParser


class T2S(object):
    def __init__(self, infile, outfile):
        self.infile = infile
        self.outfile = outfile
        self.cc = opencc.OpenCC('t2s')
        self.t_corpus = []
        self.s_corpus = []
        self.read(self.infile)
        self.t2s()
        self.write(self.s_corpus, self.outfile)

    def read(self, path):
        if os.path.isfile(path) is False:
            print("path is not a file")
            exit()
        now_line = 0
        with open(path, encoding="UTF-8") as f:
            for line in f:
                now_line += 1
                line = line.replace("\n", "").replace("\t", "")
                self.t_corpus.append(line)
        print("read finished")

    def t2s(self):
        now_line = 0
        all_line = len(self.t_corpus)
        for line in self.t_corpus:
            now_line += 1
            if now_line % 1000 == 0:
                sys.stdout.write("\rhandling with the {} line, all {} lines.".format(now_line, all_line))
            self.s_corpus.append(self.cc.convert(line))
        sys.stdout.write("\rhandling with the {} line, all {} lines.".format(now_line, all_line))
        print("\nhandling finished")

    def write(self, list, path):
        print("writing now......")
        if os.path.exists(path):
            os.remove(path)
        file = open(path, encoding="UTF-8", mode="w")
        for line in list:
            file.writelines(line + "\n")
        file.close()
        print("writing finished.")


if __name__ == "__main__":
    print("Traditional Chinese to Simplified Chinese")
    # input = "./wiki_zh_10.txt"
    # output = "wiki_zh_10_sim.txt"
    # T2S(infile=input, outfile=output)

    parser = OptionParser()
    parser.add_option("--input", dest="input", default="", help="traditional file")
    parser.add_option("--output", dest="output", default="", help="simplified file")
    (options, args) = parser.parse_args()

    input = options.input
    output = options.output

    try:
        T2S(infile=input, outfile=output)
        print("All Finished.")
    except Exception as err:
        print(err)
```



#### 清洗语料

得到的数据中包含英文，日文，德语，中文标点，乱码等一些字符，需要把这些字符清洗掉。

参考代码：

- https://github.com/bamtercelboo/corpus_process_script/blob/master/clean/clean_corpus.py

```python
import sys
import os
from optparse import OptionParser


class Clean(object):
    def __init__(self, infile, outfile):
        self.infile = infile
        self.outfile = outfile
        self.corpus = []
        self.remove_corpus = []
        self.read(self.infile)
        self.remove(self.corpus)
        self.write(self.remove_corpus, self.outfile)

    def read(self, path):
        print("reading now......")
        if os.path.isfile(path) is False:
            print("path is not a file")
            exit()
        now_line = 0
        with open(path, encoding="UTF-8") as f:
            for line in f:
                now_line += 1
                line = line.replace("\n", "").replace("\t", "")
                self.corpus.append(line)
        print("read finished.")

    def remove(self, list):
        print("removing now......")
        for line in list:
            re_list = []
            for word in line:
                if self.is_chinese(word) is False:
                    continue
                re_list.append(word)
            self.remove_corpus.append("".join(re_list))
        print("remove finished.")

    def write(self, list, path):
        print("writing now......")
        if os.path.exists(path):
            os.remove(path)
        file = open(path, encoding="UTF-8", mode="w")
        for line in list:
            file.writelines(line + "\n")
        file.close()
        print("writing finished")

    def is_chinese(self, uchar):
        """判断一个unicode是否是汉字"""
        if (uchar >= u'\u4e00') and (uchar <= u'\u9fa5'):
            return True
        else:
            return False


if __name__ == "__main__":
    print("clean corpus")

    parser = OptionParser()
    parser.add_option("--input", dest="input", default="", help="input file")
    parser.add_option("--output", dest="output", default="", help="output file")
    (options, args) = parser.parse_args()

    input = options.input
    output = options.output

    try:
        Clean(infile=input, outfile=output)
        print("All Finished.")
    except Exception as err:
        print(err)
```



### 3、清洗数据开源代码整理

参考链接：

1. [AimeeLee77](https://github.com/AimeeLee77)/**[wiki_zh_word2vec](https://github.com/AimeeLee77/wiki_zh_word2vec)**
2. [bamtercelboo](https://github.com/bamtercelboo)/**[corpus_process_script](https://github.com/bamtercelboo/corpus_process_script)**
3. [wjn1996](https://github.com/wjn1996)/**[scrapy_for_zh_wiki](https://github.com/wjn1996/scrapy_for_zh_wiki)**
4. [RaRe-Technologies](https://github.com/RaRe-Technologies)/**[gensim](https://github.com/RaRe-Technologies/gensim)**
