{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WantWords.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Lqovet7ZaLUop2WnID9vcTddIe7oj9jm","authorship_tag":"ABX9TyP7itjxgmGDfabz2mv6Mm2d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install thulac"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7JUOt9QeQT88","executionInfo":{"status":"ok","timestamp":1652073645886,"user_tz":-480,"elapsed":3861,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"5d9d5a8b-a7b4-4331-8000-722110ddec9c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: thulac in /usr/local/lib/python3.7/dist-packages (0.2.1)\n"]}]},{"cell_type":"code","source":["!pip install pytorch_transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1Es336JQj2j","executionInfo":{"status":"ok","timestamp":1652073652892,"user_tz":-480,"elapsed":3440,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"b9785e0e-0c7f-499e-8f30-23bd34de0d74"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.21.6)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.22.9)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.0.53)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (0.1.96)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.64.0)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.11.0+cu113)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (4.2.0)\n","Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.5.2)\n","Requirement already satisfied: botocore<1.26.0,>=1.25.9 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (1.25.9)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (1.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.26.0,>=1.25.9->boto3->pytorch_transformers) (1.25.11)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.26.0,>=1.25.9->boto3->pytorch_transformers) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.26.0,>=1.25.9->boto3->pytorch_transformers) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.1.0)\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"v6bgRmSXUves","executionInfo":{"status":"ok","timestamp":1652073904901,"user_tz":-480,"elapsed":9,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}}},"outputs":[],"source":["import torch, gc, json, os, thulac, string, re, requests, hashlib, urllib.parse \n","import numpy as np\n","from datetime import datetime\n","from pytorch_transformers import *\n","\n","from sklearn.cluster import KMeans\n","kmeans = KMeans(n_clusters=6, random_state=0, init='k-means++', max_iter=10)"]},{"cell_type":"code","source":["def md5(str):\n","    m = hashlib.md5()\n","    m.update(str.encode(\"utf8\"))\n","    return m.hexdigest()\n","\n","BASE_DIR = './drive/MyDrive/NLP/WantWords/'\n","\n","device = torch.device('cpu')\n","torch.backends.cudnn.benchmark = True\n","words_t = torch.tensor(np.array([0]))\n","itemsPerCol = 20\n","GET_NUM = 100\n","NUM_RESPONSE = 500\n","words_t = torch.tensor(np.array([0]))\n","\n","tokenizer_class = BertTokenizer\n","tokenizer_Ch = tokenizer_class.from_pretrained('bert-base-chinese')\n","tokenizer_En = tokenizer_class.from_pretrained('bert-base-uncased')\n","#========================ChineseRD\n","MODE = 'Psc'\n","lac = thulac.thulac()\n","\n","def load_data():\n","    (word2index, index2word, _, _, _, _, _) = np.load(BASE_DIR + 'data_features/data_inUse1.npy', allow_pickle=True)\n","    wd_charas = np.load(BASE_DIR + 'data_features/data_inUse2.npy', allow_pickle=True)\n","    ((_, _, _, wd_sems, wd_POSs),(_, mask_s)) = np.load(BASE_DIR + 'data_features/data_inUse3.npy', allow_pickle=True)\n","    mask_s = torch.from_numpy(mask_s).to(device)\n","    wd_POSs = torch.from_numpy(wd_POSs).float().to(device)\n","    wd_charas = torch.from_numpy(wd_charas).float().to(device)\n","    wd_sems = torch.from_numpy(wd_sems).float().to(device)\n","    wd_C = []\n","    mask_c = []\n","    mask_s = mask_s.float()\n","    return word2index, index2word, (wd_C, wd_sems, wd_POSs, wd_charas), (mask_c, mask_s)\n","\n","word2index, index2word, wd_features, mask_ = load_data()\n","(wd_C, wd_sems, wd_POSs, wd_charas) = wd_features\n","(mask_c, mask_s) = mask_\n","index2word = np.array(index2word)\n","\n","# 添加同义词词林用于描述为一个词时的同义词推荐\n","index2synset = [[] for i in range(len(word2index))]\n","for line in open(BASE_DIR + 'data_definition_synset/word2synset_synset.txt').readlines():\n","    wd = line.split()[0]\n","    synset = line.split()[1:]\n","    for syn in synset:\n","        index2synset[word2index[wd]].append(word2index[syn])\n","\n","MODEL_FILE = BASE_DIR + 'models/Zh.model'\n","model = torch.load(MODEL_FILE, map_location=lambda storage, loc: storage)\n","model.eval()\n","wd_data_ = json.load(open(BASE_DIR+'data_definition_synset/wd_def_for_website_zh.json'))\n","\n","#wd_data = dict()\n","wd_data = wd_data_.copy()\n","wd_defi = wd_data_.copy()\n","for wd in wd_data_:\n","    #wd_data[wd] = {'w': wd_data_[wd]['word'], 'd': wd_data_[wd]['definition'], 'P': wd_data_[wd]['POS'], 'l': wd_data_[wd]['length'], 'b': wd_data_[wd]['bihuashu'], 'B': wd_data_[wd]['bihuashu1st'], 'p': wd_data_[wd]['pinyin'], 's': wd_data_[wd]['pinyinshouzimu'], 'r': wd_data_[wd]['rhyme']}\n","    wd_data[wd] = {'w': wd_data_[wd]['word'], 'P': wd_data_[wd]['POS'], 'l': wd_data_[wd]['length'], 'b': wd_data_[wd]['bihuashu'], 'B': wd_data_[wd]['bihuashu1st'], 'p': wd_data_[wd]['pinyin'], 's': wd_data_[wd]['pinyinshouzimu'], 'r': wd_data_[wd]['rhyme']}\n","    wd_defi[wd] = wd_data_[wd]['definition']\n","del wd_data_\n"],"metadata":{"id":"jlpzVmV9VElZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652075093527,"user_tz":-480,"elapsed":18764,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"81fa808c-57a7-4500-c917-03b525d7c7f7"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded succeed\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'model.Encoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.normalization.LayerNorm' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.loss.CrossEntropyLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n"]}]},{"cell_type":"code","source":["def Score2Hexstr(score, maxsc):\n","    thr = maxsc/1.5\n","    l = len(score)\n","    ret = ['00']*l\n","    for i in range(l):\n","        res = int(200*(score[i] - thr)/thr)\n","        if res>15:\n","            ret[i] = hex(res)[2:]\n","        else:\n","            break\n","    return \n","\n","# description = request.GET['description']\n","# RD_mode = request.GET['mode']\n","description = '邓小平'\n","RD_mode = 'CC'\n","with torch.no_grad():\n","    def_words = [w for w, p in lac.cut(description)]\n","    def_word_idx = []\n","    if len(def_words) > 0:\n","        for def_word in def_words:\n","            if def_word in word2index:\n","                def_word_idx.append(word2index[def_word])\n","            else:\n","                for dw in def_word:\n","                    try:\n","                        def_word_idx.append(word2index[dw])\n","                    except:\n","                        def_word_idx.append(word2index['<OOV>'])\n","        x_len = len(def_word_idx)\n","        if set(def_word_idx)=={word2index['<OOV>']}:\n","            x_len = 1\n","        if x_len==1:\n","            if def_word_idx[0]>1:\n","                score = ((model.embedding.weight.data).mm((model.embedding.weight.data[def_word_idx[0]]).unsqueeze(1))).squeeze(1)\n","                if RD_mode=='CC':\n","                    score[def_word_idx[0]] = -10.\n","                score[np.array(index2synset[def_word_idx[0]])] *= 2\n","                sc, indices = torch.sort(score, descending=True)\n","                predicted = indices[:NUM_RESPONSE].detach().cpu().numpy()\n","                score = sc[:NUM_RESPONSE].detach().numpy()\n","                maxsc = sc[0].detach().item()\n","                s2h = Score2Hexstr(score, maxsc)\n","            else:\n","                predicted= []\n","                ret = {'error': 1} # 字符无法识别\n","        else:\n","            defi = '[CLS] ' + description\n","            def_word_idx = tokenizer_Ch.encode(defi)[:80]\n","            def_word_idx.extend(tokenizer_Ch.encode('[SEP]'))\n","            definition_words_t = torch.tensor(np.array(def_word_idx), dtype=torch.int64, device=device)\n","            definition_words_t = definition_words_t.unsqueeze(0) # batch_size = 1\n","            score = model('test', x=definition_words_t, w=words_t, ws=wd_sems, wP=wd_POSs, wc=wd_charas, wC=wd_C, msk_s=mask_s, msk_c=mask_c, mode=MODE)\n","            sc, indices = torch.sort(score, descending=True)\n","            predicted = indices[0, :NUM_RESPONSE].detach().cpu().numpy()\n","            score = sc[0, :NUM_RESPONSE].detach().numpy()\n","            maxsc = sc[0, 0].detach().item()\n","            s2h = Score2Hexstr(score, maxsc)\n","    else:\n","        predicted= []\n","        ret = {'error': 0} # 输入为空\n","if len(predicted)>0:\n","    res = index2word[predicted]\n","    ret = [] \n","    cn = -1\n","    if RD_mode=='CC':\n","        def_words = set(def_words)\n","        for wd in res:\n","            cn += 1\n","            if wd not in def_words:\n","                try:\n","                    ret.append(wd_data[wd])\n","                    ret[len(ret)-1]['c'] = s2h[cn]\n","                except:\n","                    continue\n","    else:\n","        for wd in res:\n","            cn += 1\n","            try:\n","                ret.append(wd_data[wd])\n","                ret[len(ret)-1]['c'] = s2h[cn]\n","            except:\n","                continue\n","# with open('ret.txt', 'w', encoding='utf-8') as f:\n","#     f.write(str(ret))\n","\n","for i in ret[:10]:\n","    print(i['w'])\n","    print('\\n')     "],"metadata":{"id":"oN_--tNyVzHh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652079995040,"user_tz":-480,"elapsed":563,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"98c34cf2-d1f5-4365-c038-a5b8601b0808"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["社会主义革命\n","\n","\n","新民主主义革命\n","\n","\n","南昌起义\n","\n","\n","马克思列宁主义\n","\n","\n","中共中央\n","\n","\n","毛泽东思想\n","\n","\n","中国共产党\n","\n","\n","中国工农红军\n","\n","\n","共产国际\n","\n","\n","苏区\n","\n","\n"]}]},{"cell_type":"code","source":["for i in ret[:10]:\n","    print(i['w'])\n","    print('\\n') "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-KdCx8FZ2Tt","executionInfo":{"status":"ok","timestamp":1652076047735,"user_tz":-480,"elapsed":577,"user":{"displayName":"Aspirin 007","userId":"11941172714059383624"}},"outputId":"4b899093-7662-45cf-bb9a-d126738493bd"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["杜甫\n","\n","\n","杜牧\n","\n","\n","诗仙\n","\n","\n","陶渊明\n","\n","\n","白居易\n","\n","\n","诗圣\n","\n","\n","李商隐\n","\n","\n","孟浩然\n","\n","\n","柳宗元\n","\n","\n","屈原\n","\n","\n"]}]},{"cell_type":"code","source":["def getClass2Class(r, score): \n","    perCluster = [[],[],[],[],[],[]]\n","    for i in range(GET_NUM):\n","        perCluster[r[i]].append(score[i])\n","    scorePC = []\n","    for i in range(6):\n","        l = len(perCluster[i]) if len(perCluster[i])<5 else 5\n","        scorePC.append(sum(perCluster[i][:l])/l)\n","    ind = [indsc[0] for indsc in sorted(enumerate(scorePC), key=lambda x:x[1], reverse=True)]\n","    class2class = [0,0,0,0,0,0]\n","    for i in range(6):\n","        class2class[ind[i]] = i\n","    return class2class "],"metadata":{"id":"AFPkHJOtWyik"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ChineseRDCluster(request):\n","    description = request.GET['description']\n","    RD_mode = request.GET['mode']\n","    with torch.no_grad():\n","        def_words = [w for w, p in lac.cut(description)]\n","        def_word_idx = []\n","        if len(def_words) > 0:\n","            for def_word in def_words:\n","                if def_word in word2index:\n","                    def_word_idx.append(word2index[def_word])\n","                else:\n","                    for dw in def_word:\n","                        try:\n","                            def_word_idx.append(word2index[dw])\n","                        except:\n","                            def_word_idx.append(word2index['<OOV>'])\n","            x_len = len(def_word_idx)\n","            if set(def_word_idx)=={word2index['<OOV>']}:\n","                x_len = 1\n","            if x_len==1:\n","                if def_word_idx[0]>1:\n","                    score = ((model.embedding.weight.data).mm((model.embedding.weight.data[def_word_idx[0]]).unsqueeze(1))).squeeze(1)\n","                    if RD_mode=='CC':\n","                        score[def_word_idx[0]] = -10.\n","                    score[np.array(index2synset[def_word_idx[0]])] *= 2\n","                    sc, indices = torch.sort(score, descending=True)\n","                    predicted = indices[:GET_NUM].detach().cpu().numpy()\n","                    score = sc[:GET_NUM].detach().numpy()\n","                    maxsc = sc[0].detach().item()\n","                    s2h = Score2Hexstr(score, maxsc)\n","                    r = kmeans.fit_predict(model.embedding.weight.data[predicted[:GET_NUM]].cpu().numpy()) # GET_NUM\n","                    class2class = getClass2Class(r, score[:GET_NUM])\n","                else:\n","                    predicted= []\n","                    ret = {'error': 1} # 字符无法识别\n","            else:\n","                defi = '[CLS] ' + description\n","                def_word_idx = tokenizer_Ch.encode(defi)[:80]\n","                def_word_idx.extend(tokenizer_Ch.encode('[SEP]'))\n","                definition_words_t = torch.tensor(np.array(def_word_idx), dtype=torch.int64, device=device)\n","                definition_words_t = definition_words_t.unsqueeze(0) # batch_size = 1\n","                score = model('test', x=definition_words_t, w=words_t, ws=wd_sems, wP=wd_POSs, wc=wd_charas, wC=wd_C, msk_s=mask_s, msk_c=mask_c, mode=MODE)\n","                sc, indices = torch.sort(score, descending=True)\n","                predicted = indices[0, :GET_NUM].detach().cpu().numpy()\n","                score = sc[0, :GET_NUM].detach().numpy()\n","                maxsc = sc[0, 0].detach().item()\n","                s2h = Score2Hexstr(score, maxsc)\n","                r = kmeans.fit_predict(model.embedding.weight.data[predicted[:GET_NUM]].cpu().numpy()) # GET_NUM\n","                class2class = getClass2Class(r, score[:GET_NUM])\n","        else:\n","            predicted= []\n","            ret = {'error': 0} # 输入为空\n","    if len(predicted)>0:\n","        res = index2word[predicted]\n","        ret = [] \n","        cn = -1\n","        if RD_mode=='CC':\n","            def_words = set(def_words)\n","            for wd in res:\n","                cn += 1\n","                if wd not in def_words:\n","                    try:\n","                        ret.append(wd_data[wd])\n","                        ret[len(ret)-1]['c'] = s2h[cn]\n","                        ret[len(ret)-1]['C'] = class2class[int(r[cn])] # 必须转为int，否则其实是int64类型，会报不能json序列化的错误\n","                        ret[len(ret)-1]['d'] = wd_defi[wd]\n","                        ret.sort(key=lambda x: x['C'])\n","                    except:\n","                        continue\n","        else:\n","            for wd in res:\n","                cn += 1\n","                try:\n","                    ret.append(wd_data[wd])\n","                    ret[len(ret)-1]['c'] = s2h[cn]\n","                    ret[len(ret)-1]['C'] = class2class[int(r[cn])] # 必须转为int，否则其实是int64类型，会报不能json序列化的错误\n","                    ret[len(ret)-1]['d'] = wd_defi[wd]\n","                    ret.sort(key=lambda x: x['C'])\n","                except:\n","                    continue\n","    return HttpResponse(json.dumps(ret,ensure_ascii=False),content_type=\"application/json,charset=utf-8\")"],"metadata":{"id":"zXz64RjwfjST"},"execution_count":null,"outputs":[]}]}